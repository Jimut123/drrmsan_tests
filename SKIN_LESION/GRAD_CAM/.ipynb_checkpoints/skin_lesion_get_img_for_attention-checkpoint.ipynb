{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSIIcgWFN3qn",
    "outputId": "31c2ddfa-e0bd-454b-b63c-aecf2252283b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/2/uc?id=1oPVUwkc4R_JgPUYkvVwGtUj6pHQw1bue\n",
      "To: /content/skin_lesion.zip\n",
      "50.2MB [00:02, 24.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/u/2/uc?id=1oPVUwkc4R_JgPUYkvVwGtUj6pHQw1bue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyFLo4cwN-2e"
   },
   "outputs": [],
   "source": [
    "! unzip -qq skin_lesion.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bnmIpaRrOCNt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Super More concentration\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#!/usr/bin/env python3\n",
    "# encoding: utf-8\n",
    "# @Time    : 28/02/2020 15:56\n",
    "# @Author  : Jimut Bahan Pal\n",
    "# DRRMSAN version with multi scaled alpha values\n",
    "# Just minor changes in the attention module\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add, ZeroPadding2D\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.metrics import Recall, Precision \n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/55809286/how-to-create-a-custom-keras-layer-min-pooling-but-ignore-zeros\n",
    "# Minpool2D implementation\n",
    "\n",
    "def MinPooling2D(x, pool_size, strides):\n",
    "\n",
    "    max_val = K.max(x) + 1 # we gonna replace all zeros with that value\n",
    "    # replace all 0s with very high numbers\n",
    "    is_zero = max_val * K.cast(K.equal(x,0), dtype=K.floatx())\n",
    "    x = is_zero + x\n",
    "\n",
    "    # execute pooling with 0s being replaced by a high number\n",
    "    min_x = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "\n",
    "    # depending on the value we either substract the zero replacement or not\n",
    "    is_result_zero = max_val * K.cast(K.equal(min_x, max_val), dtype=K.floatx()) \n",
    "    min_x = min_x - is_result_zero\n",
    "\n",
    "    return min_x # concatenate on channel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##=================================================\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
    "    add, multiply, AveragePooling2D, SpatialDropout2D, Subtract, average\n",
    "from tensorflow.keras import initializers\n",
    "##=================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "\n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer\n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "\n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "\n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer\n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "\n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "\n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer, filters):\n",
    "    '''\n",
    "    Attention up and concatenate layer\n",
    "\n",
    "    Arguments:\n",
    "        down_layer {keras layer} -- layer coming from the down\n",
    "        layer {keras layer} -- layer coming from the top\n",
    "        filters {int} -- number of channels in image\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "    \n",
    "    # up = Conv2DTranspose(out_channel, [3,  3], strides=[3,  3])(down_layer)\n",
    "    #up = UpSampling2D(size=(2, 2))(down_layer)\n",
    "\n",
    "    layer = proposed_attention_block_2d(down_layer, layer, filters)\n",
    "\n",
    "    # if data_format == 'channels_first':\n",
    "    #     my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
    "    # else:\n",
    "    #     my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "\n",
    "    #concate = my_concat([down_layer, layer])\n",
    "    return layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def proposed_attention_block_2d(ms_conv, res_block, filters):\n",
    "    '''\n",
    "    Proposed Attention block\n",
    "\n",
    "    Arguments:\n",
    "        ms_conv {keras layer} -- layer coming from the multi resolution convolution\n",
    "        res_block {keras layer} -- layer coming from the residual block\n",
    "        filters {int} -- number of channels in image\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    theta_x = Conv2D(filters, [2,  2], strides=[1, 1], padding='same')(ms_conv)\n",
    "    joint_conv_2x2 = Conv2D(filters, (2, 2), strides=(1, 1), padding='same')(theta_x)\n",
    "    conv_3x3 = Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(joint_conv_2x2))\n",
    "    conv_5x5 = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(joint_conv_2x2)\n",
    "    conv_5x5 = Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(conv_5x5))\n",
    "    conv_7x7 = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(joint_conv_2x2)\n",
    "    conv_7x7 = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(conv_7x7)\n",
    "    conv_7x7 = Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(conv_7x7))\n",
    "    add_3x3_5x5 = add([conv_3x3, conv_5x5])\n",
    "    mult_3x3_5x5 = multiply([conv_3x3, conv_5x5]) #multiply([conv_3x3, conv_5x5])#Subtract()([conv_3x3, conv_5x5])\n",
    "    add_3x3_5x5_7x7 = Activation('relu')(add([add_3x3_5x5, conv_7x7]))\n",
    "    mul_3x3_5x5_7x7 = Activation('relu')(multiply([mult_3x3_5x5, conv_7x7]))#multiply([mult_3x3_5x5, conv_7x7]))) # Subtract()([mult_3x3_5x5, conv_7x7])\n",
    "    add_1x1_upper = Activation('relu')(Conv2D(filters, [2,  2], strides=[1, 1], padding='same')(add_3x3_5x5_7x7))\n",
    "    mult_1x1_lower = Activation('relu')(Conv2D(filters, [2,  2], strides=[1, 1], padding='same')(mul_3x3_5x5_7x7))\n",
    "    resampler_down_upper = MaxPooling2D(pool_size=(12, 12), strides=(2, 2))(add_1x1_upper) #AveragePooling2D\n",
    "    resampler_down_lower = MaxPooling2D(pool_size=(12, 12), strides=(2, 2))(mult_1x1_lower)\n",
    "    output_ms_conv_res_block = multiply([resampler_down_upper, resampler_down_lower])\n",
    "\n",
    "    theta_x_rb = Conv2D(filters, [2,  2], strides=[1, 1], padding='same')(res_block)\n",
    "    joint_conv_2x2_rb = Conv2D(filters, (2, 2), strides=(1, 1), padding='same')(theta_x_rb)\n",
    "    conv_3x3_rb = Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(joint_conv_2x2_rb))\n",
    "    conv_5x5_rb = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(joint_conv_2x2_rb)\n",
    "    conv_5x5_rb = Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(conv_5x5_rb))\n",
    "    conv_7x7_rb = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(joint_conv_2x2_rb)\n",
    "    conv_7x7_rb = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(conv_7x7_rb)\n",
    "    conv_7x7_rb = Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(conv_7x7_rb))\n",
    "    add_3x3_5x5_rb = add([conv_3x3_rb, conv_5x5_rb])\n",
    "    mult_3x3_5x5_rb = multiply([conv_3x3_rb, conv_5x5_rb])#multiply([conv_3x3_rb, conv_5x5_rb]) #Subtract()([conv_3x3_rb, conv_5x5_rb])\n",
    "    add_3x3_5x5_7x7_rb = Activation('relu')(add([add_3x3_5x5_rb, conv_7x7_rb]))\n",
    "    mul_3x3_5x5_7x7_rb = Activation('relu')(multiply([mult_3x3_5x5_rb, conv_7x7_rb]))#multiply([mult_3x3_5x5_rb, conv_7x7_rb]))) # Subtract()([mult_3x3_5x5_rb, conv_7x7_rb])\n",
    "    add_1x1_upper_rb = Activation('relu')(Conv2D(filters, [2,  2], strides=[1, 1], padding='same')(add_3x3_5x5_7x7_rb))\n",
    "    mult_1x1_lower_rb = Activation('relu')(Conv2D(filters, [2, 2], strides=[1, 1], padding='same', )(mul_3x3_5x5_7x7_rb))\n",
    "    resampler_down_upper_rb = MaxPooling2D(pool_size=(12, 12), strides=(2, 2))(add_1x1_upper_rb)\n",
    "    resampler_down_lower_rb = MaxPooling2D(pool_size=(12, 12), strides=(2, 2))(mult_1x1_lower_rb)\n",
    "    output_ms_conv_res_block_rb = multiply([resampler_down_upper_rb, resampler_down_lower_rb])\n",
    "    \n",
    "    attn_outputs_mult = Activation('sigmoid')(multiply([output_ms_conv_res_block, output_ms_conv_res_block_rb]))\n",
    "    attn_output_1 = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(ZeroPadding2D(padding=(5,5))(UpSampling2D(size=(2, 2))(attn_outputs_mult)))\n",
    "\n",
    "    theta_x_rb = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(theta_x_rb)\n",
    "    attn_output = multiply([attn_output_1, theta_x_rb])\n",
    "    return attn_output_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "\n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer\n",
    "\n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
    "def rec_res_block(input_layer, filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1], padding='same'):\n",
    "    skip_layer = input_layer\n",
    "    layer = skip_layer\n",
    "    for j in range(2):\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                layer1 = Conv2D(filters, kernel_size, strides=stride, padding=padding)(layer)\n",
    "                if batch_normalization:\n",
    "                    layer1 = BatchNormalization()(layer1)\n",
    "                layer1 = Activation('relu')(layer1)\n",
    "            layer1 = Conv2D(filters, kernel_size, strides=stride, padding=padding)(add([layer1, layer]))\n",
    "            if batch_normalization:\n",
    "                layer1 = BatchNormalization()(layer1)\n",
    "            layer1 = Activation('relu')(layer1)\n",
    "        layer = layer1\n",
    "    out_layer = add([layer, skip_layer])\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "\n",
    "def DRRMSAN_multiscale_attention_bayes_022(height, width, n_channels, alpha_1, alpha_2, alpha_3, alpha_4):\n",
    "    '''\n",
    "    DRRMSAN Multiscale Attention Model\n",
    "\n",
    "    Arguments:\n",
    "        height {int} -- height of image\n",
    "        width {int} -- width of image\n",
    "        n_channels {int} -- number of channels in image\n",
    "\n",
    "    Returns:\n",
    "        [keras model] -- MultiResUNet model\n",
    "    '''\n",
    "    print(\"DRRMSAN Bayes\")\n",
    "\n",
    "\n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    # use average pool, maxpool and minpool to create different volumes of\n",
    "    # multiscaling, minpool is used here as a sort of regularizer noise in the feature\n",
    "    # space.  1/2 th the original scale first.\n",
    "\n",
    "    inp_1_2I = AveragePooling2D(pool_size=(2, 2))(inputs)\n",
    "    inp_1_2I_mxpool = MaxPooling2D(pool_size=(2, 2))(inputs)\n",
    "    inp_1_2I_minpool = MinPooling2D(inputs, pool_size=(2,2), strides=(1,1))\n",
    "\n",
    "\n",
    "    # 1/4 rth the original scale\n",
    "    inp_1_4I = AveragePooling2D(pool_size=(2, 2))(inp_1_2I)\n",
    "    inp_1_4I_mxpool = MaxPooling2D(pool_size=(2, 2))(inp_1_2I_mxpool)\n",
    "    inp_1_4I_minpool = MinPooling2D(inp_1_2I_minpool, pool_size=(2,2), strides=(1,1))\n",
    "    #inp_1_4I_minpool = MaxPooling2D(pool_size=(2, 2))(inp_1_2I_mxpool)\n",
    "\n",
    "    # 1/8 th the original scale\n",
    "    inp_1_8I = AveragePooling2D(pool_size=(2, 2))(inp_1_4I)\n",
    "    inp_1_8I_mxpool = MaxPooling2D(pool_size=(2, 2))(inp_1_4I_mxpool)\n",
    "    inp_1_8I_minpool = MinPooling2D(inp_1_4I_minpool, pool_size=(2,2), strides=(1,1))\n",
    "    \n",
    "    # just pass through some conv and add\n",
    "    # for adding to multi res block 2, 32 filters\n",
    "    # use 50 - 50 \n",
    "    # Conv2D(filters, (3, 3), strides=(1,1), padding='same'\n",
    "    \n",
    "    # using different ratios for the volumes, can be improved by using\n",
    "    # Bayesian Optimization\n",
    "\n",
    "    total_1_2I = 51\n",
    "    per_mx_pool_1_2I = int(0.05 * total_1_2I)\n",
    "    per_avg_pool_1_2I = int(0.05 * total_1_2I)\n",
    "    per_min_pool_1_2I = int(0.40 * total_1_2I)\n",
    "    per_down_1_2I = int(total_1_2I - (per_mx_pool_1_2I + per_avg_pool_1_2I + per_min_pool_1_2I))\n",
    "\n",
    "    mrb2_1_2I_avgpool = Conv2D(per_avg_pool_1_2I, (3, 3), strides=(1,1), padding='same', name='side_left_1_avgpool')(inp_1_2I) \n",
    "    mrb2_1_2I_mxpool = Conv2D(per_mx_pool_1_2I, (3, 3), strides=(1,1), padding='same', name='side_left_1_mxpool')(inp_1_2I_mxpool)\n",
    "    mrb2_1_2I_minpool = Conv2D(per_min_pool_1_2I, (3, 3), strides=(1,1), padding='same', name='side_left_1_minpool')(inp_1_2I_minpool)\n",
    "\n",
    "    total_1_4I = 105\n",
    "    per_mx_pool_1_4I = int(0.05 * total_1_4I)\n",
    "    per_avg_pool_1_4I = int(0.05 * total_1_4I)\n",
    "    per_min_pool_1_4I = int(0.40 * total_1_4I)\n",
    "    # 52% to the down layer\n",
    "    per_down_1_4I = int(total_1_4I - (per_mx_pool_1_4I + per_avg_pool_1_4I + per_min_pool_1_4I))\n",
    "\n",
    "    mrb3_1_4I_avgpool = Conv2D(per_avg_pool_1_4I, (3, 3), strides=(1,1), padding='same', name='side_left_2_avgpool')(inp_1_4I) \n",
    "    mrb3_1_4I_mxpool = Conv2D(per_mx_pool_1_4I, (3, 3), strides=(1,1), padding='same', name='side_left_2_mxpool')(inp_1_4I_mxpool) \n",
    "    mrb3_1_4I_minpool = Conv2D(per_min_pool_1_4I, (3, 3), strides=(1,1), padding='same', name='side_left_2_minpool')(inp_1_4I_minpool) \n",
    "\n",
    "    total_1_8I = 212\n",
    "    per_mx_pool_1_8I = int(0.05 * total_1_8I)\n",
    "    per_avg_pool_1_8I = int(0.05 * total_1_8I)\n",
    "    per_min_pool_1_8I = int(0.40 * total_1_8I)\n",
    "    per_down_1_8I = int(total_1_8I - (per_mx_pool_1_8I + per_avg_pool_1_8I + per_min_pool_1_8I))\n",
    "\n",
    "    mrb4_1_8I_avgpool = Conv2D(per_avg_pool_1_8I, (3, 3), strides=(1,1), padding='same', name='side_left_3_avgpool')(inp_1_8I)\n",
    "    mrb4_1_8I_mxpool = Conv2D(per_mx_pool_1_8I, (3, 3), strides=(1,1), padding='same', name='side_left_3_mxpool')(inp_1_8I_mxpool)\n",
    "    mrb4_1_8I_minpool = Conv2D(per_min_pool_1_8I, (3, 3), strides=(1,1), padding='same', name='side_left_3_minpool')(inp_1_8I_minpool)\n",
    "\n",
    "\n",
    "    #==================================================================\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    #mresblock1 = rec_res_block(mresblock1, 51)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    #===================\n",
    "    pool1 = Conv2D(per_down_1_2I, (3, 3), strides=(1,1), padding='same')(pool1)\n",
    "    left_block_1 = concatenate([pool1, mrb2_1_2I_avgpool, mrb2_1_2I_mxpool, mrb2_1_2I_minpool])\n",
    "    #left_block_1 = rec_res_block(left_block_1, total_1_2I)\n",
    "    #pool1 = multiply([pool1, mrb2_1_2I])\n",
    "    #pool1 = proposed_attention_block_2d(pool1, mresblock1,filters=51)\n",
    "    #===================\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    \n",
    "    mresblock2 = MultiResBlock(32*2, left_block_1)\n",
    "    #mresblock2 = rec_res_block(mresblock2, 105)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    #===================\n",
    "    pool2 = Conv2D(per_down_1_4I, (3, 3), strides=(1,1), padding='same')(pool2)\n",
    "    left_block_2 = concatenate([pool2, mrb3_1_4I_avgpool, mrb3_1_4I_mxpool, mrb3_1_4I_minpool])\n",
    "    #left_block_2 = rec_res_block(left_block_2, total_1_4I)\n",
    "    #pool2 = multiply([pool2, mrb3_1_4I])\n",
    "    #pool2 = proposed_attention_block_2d(pool2, mresblock2,filters=105)\n",
    "    #===================\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, left_block_2)\n",
    "    #mresblock3 = rec_res_block(mresblock3, 212)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    #===================\n",
    "    pool3 = Conv2D(per_down_1_8I, (3, 3), strides=(1,1), padding='same')(pool3)\n",
    "    left_block_3 = concatenate([pool3, mrb4_1_8I_avgpool, mrb4_1_8I_mxpool, mrb4_1_8I_minpool])\n",
    "    #left_block_3 = rec_res_block(left_block_3, total_1_8I)\n",
    "    #pool3 = multiply([pool3, mrb4_1_8I])\n",
    "    #pool3 = proposed_attention_block_2d(pool3, mresblock3,filters=212)\n",
    "    #===================\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, left_block_3)\n",
    "    #mresblock4 = rec_res_block(mresblock4, 426)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
    "\n",
    "\n",
    "    mresblock5 = MultiResBlock(32*16, pool4)\n",
    "    #mresblock5 = rec_res_block(mresblock5, 853)\n",
    "\n",
    "    #up6_add =  add([Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4])\n",
    "    #up6_dra = attention_up_and_concate(Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same', name='up6_dra')(mresblock5), mresblock4,filters=32*8)\n",
    "    up6 = proposed_attention_block_2d(Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same', name='up6')(mresblock5), mresblock4,filters=256)\n",
    "    \n",
    "    up6 = add([up6, mresblock4])\n",
    "    \n",
    "    #concatenate([Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*8, up6)\n",
    "    #mresblock6 = rec_res_block(mresblock6, 426)\n",
    "    conv_6_up = Conv2D(212, (3, 3), padding='same', activation='relu', name='conv_6_up')(mresblock6)\n",
    "    #conv_6_up = rec_res_block(mresblock6, 426)\n",
    "    \n",
    "\n",
    "    #up7_add = add([Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3])\n",
    "    #up7_dra = attention_up_and_concate(Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same', name='up7_dra')(mresblock6), mresblock3, filters = 32*4)\n",
    "    up7 = proposed_attention_block_2d(Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same', name='up7')(mresblock6), mresblock3, filters = 32*4)\n",
    "    up7 = add([up7, mresblock3])\n",
    "    mresblock7 = MultiResBlock(32*4, up7)\n",
    "    #mresblock7 = rec_res_block(mresblock7, 212)\n",
    "    conv_7_up = Conv2D(105, (3, 3), padding='same', activation='relu', name='conv_7_up')(mresblock7)\n",
    "    #conv_7_up = rec_res_block(mresblock7, 212)\n",
    "    \n",
    "\n",
    "    #up8_add = add([Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2])\n",
    "    #up8_dra = attention_up_and_concate(Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same', name='up8_dra')(mresblock7), mresblock2, filters = 32*2)\n",
    "    up8 = proposed_attention_block_2d(Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same', name='up8')(mresblock7), mresblock2, filters = 32*2)\n",
    "    up8 = concatenate([up8, mresblock2])#,\n",
    "    mresblock8 = MultiResBlock(32*2, up8)\n",
    "    #mresblock8 = rec_res_block(mresblock8, 105)\n",
    "    conv_8_up = Conv2D(51, (3, 3), padding='same', activation='relu', name='conv_8_up')(mresblock8)\n",
    "    #conv_8_up = rec_res_block(conv_8_up, 51)\n",
    "\n",
    "    #up9_add = add([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(mresblock8), mresblock1])\n",
    "    #up9_dra = attention_up_and_concate(Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', name='up9_dra')(mresblock8), mresblock1, filters = 32)\n",
    "    up9 = proposed_attention_block_2d(Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', name='up9')(mresblock8), mresblock1, filters = 32)\n",
    "    up9 = add([up9, mresblock1])#\n",
    "    mresblock9 = MultiResBlock(32, up9)\n",
    "    #mresblock9 = rec_res_block(mresblock9, 51)\n",
    "    conv_9_up = Conv2D(32, (3, 3), padding='same', activation='relu', name='conv_8_up')(mresblock9)\n",
    "    #conv_9_up = rec_res_block(conv_9_up, 32)\n",
    "\n",
    "\n",
    "    side6 = UpSampling2D(size=(8, 8))(conv_6_up)\n",
    "    side7 = UpSampling2D(size=(4, 4))(conv_7_up)\n",
    "    side8 = UpSampling2D(size=(2, 2))(conv_8_up)\n",
    "\n",
    "    # the conv blocks on the right sides\n",
    "\n",
    "    out6 = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='side_6')(side6) # conv2d_bn(side6, 1, 1, 1, activation='none') #\n",
    "    out7 = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='side_7')(side7) # conv2d_bn(side7, 1, 1, 1, activation='none') #\n",
    "    out8 = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='side_8')(side8) # conv2d_bn(side8, 1, 1, 1, activation='none') #\n",
    "\n",
    "    out9 = conv2d_bn(mresblock9, 1, 3, 3, activation='sigmoid', padding='same')\n",
    "\n",
    "    # weighted averaging all the output masks obtained at different scales\n",
    "    # alpha_1 = least scale, alpha_4 = same scale as I\n",
    "\n",
    "    #out10 = Conv2D(1, (3, 3), activation='sigmoid', padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4), name='out_10')(add([alpha_1 * out6, alpha_2 * out7, alpha_3 * out8, alpha_4 * out9]))\n",
    "    out10 = add([alpha_1 * out6, alpha_2 * out7, alpha_3 * out8, alpha_4 * out9])\n",
    "\n",
    "    #conv10 = conv2d_bn(out10, 1, 1, 1, activation='sigmoid')\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[out6, out7, out8, out9, out10])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FzUQiPY7Omwa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjkC94dbOmtU",
    "outputId": "583f1d92-3eb9-4c1c-d80a-cdebbf359545"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 2432.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainx/X_img_0.bmp', 'trainx/X_img_1.bmp', 'trainx/X_img_10.bmp', 'trainx/X_img_100.bmp', 'trainx/X_img_101.bmp', 'trainx/X_img_102.bmp', 'trainx/X_img_103.bmp', 'trainx/X_img_104.bmp', 'trainx/X_img_105.bmp', 'trainx/X_img_106.bmp']\n",
      "['trainy/Y_img_0.bmp', 'trainy/Y_img_1.bmp', 'trainy/Y_img_10.bmp', 'trainy/Y_img_100.bmp', 'trainy/Y_img_101.bmp', 'trainy/Y_img_102.bmp', 'trainy/Y_img_103.bmp', 'trainy/Y_img_104.bmp', 'trainy/Y_img_105.bmp', 'trainy/Y_img_106.bmp']\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# encoding: utf-8\n",
    "# @Time    : 24/03/2021 20:09\n",
    "# @Author  : Jimut Bahan Pal\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import average_precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_files = glob.glob('trainx/*.bmp')\n",
    "msk_files = glob.glob('trainy/*.bmp')\n",
    "\n",
    "img_files.sort()\n",
    "msk_files.sort()\n",
    "print(img_files[:10])\n",
    "print(msk_files[:10])\n",
    "print(len(img_files))\n",
    "print(len(msk_files))\n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img_fl in tqdm(img_files):\n",
    "    if(img_fl.split('.')[-1]=='bmp'):\n",
    "        # print(img_fl)\n",
    "        img = cv2.imread('{}'.format(img_fl), cv2.IMREAD_COLOR)\n",
    "        X.append(img) #resized_img)\n",
    "        img_msk = \"trainy/Y_img_\"+str(img_fl.split('.')[0]).split('_')[-1]+\".bmp\"\n",
    "        # print(img_msk)\n",
    "        msk = cv2.imread('{}'.format(img_msk), cv2.IMREAD_GRAYSCALE)\n",
    "        Y.append(msk)#resized_msk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "od1YpkMWOCKn",
    "outputId": "47875921-0489-44c3-98b1-41a761c215c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "(160, 192, 256)\n",
      "(160, 192, 256, 3)\n",
      "(160, 192, 256, 1)\n",
      "(40, 192, 256, 3)\n",
      "(40, 192, 256, 1)\n",
      "DRRMSAN Bayes\n",
      "20/20 [==============================] - 67s 3s/step\n",
      "Jacard Index : 0.8599550795873252\n",
      "Dice Coefficient : 0.9152689312106412\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "fold_no = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    fold_no += 1\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
    "    print(Y_train.shape)\n",
    "\n",
    "    Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
    "\n",
    "\n",
    "    Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
    "\n",
    "\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "    Y_train = Y_train / 255\n",
    "    Y_test = Y_test / 255\n",
    "\n",
    "    Y_train = np.round(Y_train,0)\t\n",
    "    Y_test = np.round(Y_test,0)\t\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "\n",
    "    def dice_coef(y_true, y_pred):\n",
    "        smooth = 0.0\n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "    def jacard(y_true, y_pred):\n",
    "\n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        intersection = K.sum ( y_true_f * y_pred_f)\n",
    "        union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
    "\n",
    "        return intersection/union\n",
    "\n",
    "\n",
    "    jaccard_index_list = []\n",
    "    dice_coeff_list = []\n",
    "\n",
    "    def evaluateModel(model, X_test, Y_test, batchSize):\n",
    "\n",
    "        try:\n",
    "            os.makedirs('images_attention')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
    "\n",
    "        yp = np.round(yp,0)\n",
    "        yp = yp[4]\n",
    "\n",
    "        for i in range(30):\n",
    "            str_img = 'images_attention/img_'+str(i)+'.png'\n",
    "            cv2.imwrite(str_img, X_test[i]*255)\n",
    "            str_gt = 'images_attention/gt_'+str(i)+'.png'\n",
    "            cv2.imwrite(str_gt, Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1])*255)\n",
    "            str_pred = 'images_attention/pred_'+str(i)+'.png'\n",
    "            cv2.imwrite(str_pred, yp[i].reshape(yp[i].shape[0],yp[i].shape[1])*255)\n",
    "            \n",
    "\n",
    "            intersection = yp[i].ravel() * Y_test[i].ravel()\n",
    "            union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
    "\n",
    "            avg_precision = average_precision_score(yp[i].ravel(), Y_test[i].ravel())\n",
    "            dice = (2. * np.sum(intersection)) / (np.sum(yp[i].ravel()) + np.sum(Y_test[i].ravel()))\n",
    "\n",
    "            jacard = (np.sum(intersection)/np.sum(union))\n",
    "            \n",
    "        \n",
    "        jacard = 0\n",
    "        dice = 0\n",
    "        avg_precision = 0\n",
    "        recall_score = 0\n",
    "\n",
    "        for i in range(len(Y_test)):\n",
    "            yp_2 = yp[i].ravel()\n",
    "            y2 = Y_test[i].ravel()\n",
    "\n",
    "            intersection = yp_2 * y2\n",
    "            union = yp_2 + y2 - intersection\n",
    "            avg_precision += average_precision_score(yp_2, y2)\n",
    "            # recall_score += recall_score(yp_2, y2)\n",
    "\n",
    "            jacard += (np.sum(intersection)/np.sum(union))\n",
    "\n",
    "            dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "\n",
    "        jacard /= len(Y_test)\n",
    "        dice /= len(Y_test)\n",
    "        avg_precision /= len(Y_test)\n",
    "        # recall_score /= len(Y_test)\n",
    "\n",
    "        print('Jacard Index : '+str(jacard))\n",
    "        print('Dice Coefficient : '+str(dice))\n",
    "        with open(\"Output_attn.txt\", \"a\") as text_file:\n",
    "            text_file.write(\"Fold = {} Jacard : {} Dice Coef : {} Avg. Precision : {}  \\n\".format(str(fold_no), \n",
    "            str(jacard), str(dice), str(avg_precision)))\n",
    "        \n",
    "\n",
    "        jaccard_index_list.append(jacard)\n",
    "        dice_coeff_list.append(dice)\n",
    "        \n",
    "\n",
    "\n",
    "    def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
    "        evaluateModel(model,X_test, Y_test,batchSize)\n",
    "        return model\n",
    "        \n",
    "    # img_w, img_h, n_label, data_format='channels_first'\n",
    "    alpha_1 = 0.25\n",
    "    alpha_2 = 0.25\n",
    "    alpha_3 = 0.25\n",
    "    alpha_4 = 0.25\n",
    "\n",
    "    model = DRRMSAN_multiscale_attention_bayes_022(height=192, width=256, n_channels=3, alpha_1 = alpha_1, alpha_2 = alpha_2, alpha_3 = alpha_3, alpha_4 = alpha_4)\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5),loss='binary_crossentropy',metrics=[dice_coef, jacard, Recall(), Precision(), 'accuracy'])\n",
    "    model.load_weights('modelW_drrmsan_skinLesion.h5')\n",
    "    \n",
    "    trainStep(model, X_train, Y_train, X_test, Y_test, epochs=150, batchSize=2)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjoIK_rbOSIW",
    "outputId": "093efc2c-49bf-41f4-a9aa-396de0cd7303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: images_attention/ (stored 0%)\n",
      "  adding: images_attention/img_11.png (deflated 0%)\n",
      "  adding: images_attention/img_7.png (deflated 0%)\n",
      "  adding: images_attention/gt_16.png (deflated 14%)\n",
      "  adding: images_attention/img_23.png (deflated 0%)\n",
      "  adding: images_attention/gt_2.png (deflated 22%)\n",
      "  adding: images_attention/img_5.png (deflated 0%)\n",
      "  adding: images_attention/pred_4.png (deflated 25%)\n",
      "  adding: images_attention/img_16.png (deflated 0%)\n",
      "  adding: images_attention/pred_12.png (deflated 18%)\n",
      "  adding: images_attention/img_22.png (deflated 0%)\n",
      "  adding: images_attention/gt_15.png (deflated 4%)\n",
      "  adding: images_attention/img_12.png (deflated 1%)\n",
      "  adding: images_attention/img_19.png (deflated 0%)\n",
      "  adding: images_attention/pred_9.png (deflated 28%)\n",
      "  adding: images_attention/gt_10.png (deflated 35%)\n",
      "  adding: images_attention/pred_26.png (deflated 8%)\n",
      "  adding: images_attention/img_21.png (deflated 0%)\n",
      "  adding: images_attention/img_4.png (deflated 0%)\n",
      "  adding: images_attention/pred_11.png (deflated 36%)\n",
      "  adding: images_attention/pred_28.png (deflated 18%)\n",
      "  adding: images_attention/pred_18.png (deflated 8%)\n",
      "  adding: images_attention/gt_9.png (deflated 29%)\n",
      "  adding: images_attention/img_3.png (deflated 0%)\n",
      "  adding: images_attention/gt_23.png (deflated 5%)\n",
      "  adding: images_attention/pred_1.png (deflated 20%)\n",
      "  adding: images_attention/img_25.png (deflated 0%)\n",
      "  adding: images_attention/pred_22.png (deflated 26%)\n",
      "  adding: images_attention/gt_5.png (deflated 6%)\n",
      "  adding: images_attention/img_13.png (deflated 0%)\n",
      "  adding: images_attention/img_26.png (deflated 0%)\n",
      "  adding: images_attention/pred_7.png (deflated 15%)\n",
      "  adding: images_attention/pred_20.png (deflated 12%)\n",
      "  adding: images_attention/gt_22.png (deflated 22%)\n",
      "  adding: images_attention/gt_17.png (deflated 5%)\n",
      "  adding: images_attention/gt_21.png (deflated 6%)\n",
      "  adding: images_attention/pred_16.png (deflated 11%)\n",
      "  adding: images_attention/gt_8.png (deflated 16%)\n",
      "  adding: images_attention/gt_4.png (deflated 24%)\n",
      "  adding: images_attention/img_29.png (deflated 0%)\n",
      "  adding: images_attention/img_2.png (deflated 0%)\n",
      "  adding: images_attention/gt_3.png (deflated 8%)\n",
      "  adding: images_attention/pred_14.png (deflated 13%)\n",
      "  adding: images_attention/gt_26.png (deflated 26%)\n",
      "  adding: images_attention/pred_17.png (deflated 5%)\n",
      "  adding: images_attention/gt_14.png (deflated 11%)\n",
      "  adding: images_attention/img_8.png (deflated 0%)\n",
      "  adding: images_attention/img_9.png (deflated 0%)\n",
      "  adding: images_attention/pred_2.png (deflated 19%)\n",
      "  adding: images_attention/pred_25.png (deflated 21%)\n",
      "  adding: images_attention/img_0.png (deflated 0%)\n",
      "  adding: images_attention/gt_24.png (deflated 26%)\n",
      "  adding: images_attention/pred_19.png (deflated 10%)\n",
      "  adding: images_attention/gt_0.png (deflated 11%)\n",
      "  adding: images_attention/pred_27.png (deflated 4%)\n",
      "  adding: images_attention/pred_21.png (deflated 12%)\n",
      "  adding: images_attention/pred_13.png (deflated 6%)\n",
      "  adding: images_attention/img_10.png (deflated 0%)\n",
      "  adding: images_attention/pred_8.png (deflated 3%)\n",
      "  adding: images_attention/gt_18.png (deflated 19%)\n",
      "  adding: images_attention/pred_15.png (deflated 15%)\n",
      "  adding: images_attention/gt_11.png (deflated 34%)\n",
      "  adding: images_attention/img_15.png (deflated 1%)\n",
      "  adding: images_attention/gt_28.png (deflated 28%)\n",
      "  adding: images_attention/img_14.png (deflated 1%)\n",
      "  adding: images_attention/gt_25.png (deflated 13%)\n",
      "  adding: images_attention/gt_7.png (deflated 25%)\n",
      "  adding: images_attention/pred_6.png (deflated 30%)\n",
      "  adding: images_attention/img_18.png (deflated 0%)\n",
      "  adding: images_attention/img_17.png (deflated 0%)\n",
      "  adding: images_attention/gt_12.png (deflated 14%)\n",
      "  adding: images_attention/pred_23.png (deflated 4%)\n",
      "  adding: images_attention/gt_6.png (deflated 19%)\n",
      "  adding: images_attention/gt_27.png (deflated 21%)\n",
      "  adding: images_attention/img_20.png (deflated 0%)\n",
      "  adding: images_attention/gt_19.png (deflated 20%)\n",
      "  adding: images_attention/gt_29.png (deflated 8%)\n",
      "  adding: images_attention/img_28.png (deflated 0%)\n",
      "  adding: images_attention/img_6.png (deflated 0%)\n",
      "  adding: images_attention/pred_0.png (deflated 23%)\n",
      "  adding: images_attention/img_27.png (deflated 0%)\n",
      "  adding: images_attention/pred_24.png (deflated 28%)\n",
      "  adding: images_attention/pred_29.png (deflated 10%)\n",
      "  adding: images_attention/img_24.png (deflated 0%)\n",
      "  adding: images_attention/gt_1.png (deflated 18%)\n",
      "  adding: images_attention/img_1.png (deflated 0%)\n",
      "  adding: images_attention/gt_20.png (deflated 17%)\n",
      "  adding: images_attention/pred_3.png (deflated 25%)\n",
      "  adding: images_attention/gt_13.png (deflated 1%)\n",
      "  adding: images_attention/pred_5.png (deflated 15%)\n",
      "  adding: images_attention/pred_10.png (deflated 36%)\n"
     ]
    }
   ],
   "source": [
    "! zip -r images_attention.zip images_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnQGLCBwZ9da"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "skin_lesion_get_img_for_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
